#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import ollama
import json
import time
import os
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from tqdm import tqdm

from .prompts import get_translation_prompt

class OllamaTranslator:
    """Ollama Python ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•œ ì˜ì–´â†’í•œêµ­ì–´ ë²ˆì—­ê¸°"""
    
    def __init__(self, 
                 model_name="llama3.1:8b",
                 temperature=0.1,
                 max_retries=3,
                 genre="fantasy"):
        """
        Args:
            model_name: ì‚¬ìš©í•  Ollama ëª¨ë¸ëª…
            temperature: ë²ˆì—­ ì¼ê´€ì„±ì„ ìœ„í•œ ë‚®ì€ ì˜¨ë„ê°’ (0.0-2.0)
            max_retries: ë²ˆì—­ ì‹¤íŒ¨ì‹œ ì¬ì‹œë„ íšŸìˆ˜
            genre: ì†Œì„¤ ì¥ë¥´ (fantasy, sci-fi, romance, mystery, general)
        """
        self.model_name = model_name
        self.temperature = temperature
        self.max_retries = max_retries
        self.genre = genre
        
        # Ollama í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = ollama.Client()
        
        # ì¥ë¥´ë³„ ë²ˆì—­ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        self.translation_prompt = get_translation_prompt(genre)
    
    def check_ollama_available(self) -> bool:
        """Ollama ì„œë¹„ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        try:
            # ê°„ë‹¨í•œ API í˜¸ì¶œë¡œ Ollama ì„œë¹„ìŠ¤ í™•ì¸
            self.client.list()
            return True
        except Exception:
            return False
    
    def check_model_available(self) -> bool:
        """ì§€ì •ëœ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        try:
            models = self.client.list()
            model_names = []
            for model in models.get('models', []):
                # API ì‘ë‹µ êµ¬ì¡°ì— ë”°ë¼ ë‹¤ë¥¸ í•„ë“œëª… ì‹œë„
                if hasattr(model, 'model'):
                    model_names.append(model.model)
                elif 'model' in model:
                    model_names.append(model['model'])
                elif 'name' in model:
                    model_names.append(model['name'])
            return self.model_name in model_names
        except Exception as e:
            print(f"ëª¨ë¸ í™•ì¸ ì˜¤ë¥˜: {e}")
            return False
    
    def ensure_model_loaded(self) -> bool:
        """ëª¨ë¸ì´ ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ë¡œë“œ"""
        try:
            # ì§§ì€ í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ëª¨ë¸ ë¡œë“œ í™•ì¸
            test_response = self.client.generate(
                model=self.model_name,
                prompt="Hello",
                options={'num_predict': 1}  # 1í† í°ë§Œ ìƒì„±
            )
            return True
        except Exception as e:
            print(f"ëª¨ë¸ ë¡œë“œ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False
    
    def translate_text(self, text: str) -> Optional[str]:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¸”ë¡ ë²ˆì—­"""
        if not text.strip():
            return ""
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.translation_prompt.format(text=text.strip())
        
        for attempt in range(self.max_retries):
            try:
                # Ollama Python í´ë¼ì´ì–¸íŠ¸ë¡œ ë²ˆì—­ ìš”ì²­
                response = self.client.generate(
                    model=self.model_name,
                    prompt=prompt,
                    options={
                        'temperature': self.temperature,
                        'top_p': 0.9,
                        'top_k': 40,
                        'repeat_penalty': 1.1
                    }
                )
                
                translation = response.get('response', '').strip()
                if translation:
                    return translation
                else:
                    print(f"ê²½ê³ : ë¹ˆ ë²ˆì—­ ê²°ê³¼ (ì‹œë„ {attempt + 1}/{self.max_retries})")
                    
            except ollama.ResponseError as e:
                print(f"Ollama ì‘ë‹µ ì˜¤ë¥˜: {e} (ì‹œë„ {attempt + 1}/{self.max_retries})")
                if "model" in str(e).lower() and "not found" in str(e).lower():
                    print(f"ëª¨ë¸ '{self.model_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    print("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: ollama list")
                    break
            except ollama.RequestError as e:
                print(f"Ollama ìš”ì²­ ì˜¤ë¥˜: {e} (ì‹œë„ {attempt + 1}/{self.max_retries})")
                if "connection" in str(e).lower():
                    print("Ollama ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    print("ì„œë¹„ìŠ¤ ì‹œì‘: ollama serve")
                    break
            except Exception as e:
                print(f"ë²ˆì—­ ì˜¤ë¥˜: {e} (ì‹œë„ {attempt + 1}/{self.max_retries})")
            
            if attempt < self.max_retries - 1:
                time.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
        
        print(f"ì˜¤ë¥˜: {self.max_retries}ë²ˆ ì‹œë„ í›„ ë²ˆì—­ ì‹¤íŒ¨")
        return None
    
    def translate_chunks(self, input_dir: str, output_dir: str) -> Dict[str, any]:
        """ì²­í¬ ë””ë ‰í† ë¦¬ ì „ì²´ ë²ˆì—­"""
        input_path = Path(input_dir)
        output_path = Path(output_dir)
        
        # ì…ë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
        if not input_path.exists():
            raise FileNotFoundError(f"ì…ë ¥ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
        
        chunks_dir = input_path / "chunks"
        if not chunks_dir.exists():
            raise FileNotFoundError(f"ì²­í¬ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {chunks_dir}")
        
        # ì²­í¬ ì¸ë±ìŠ¤ ë¡œë“œ
        chunk_index_file = chunks_dir / "chunk_index.json"
        if not chunk_index_file.exists():
            raise FileNotFoundError(f"ì²­í¬ ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {chunk_index_file}")
        
        with open(chunk_index_file, 'r', encoding='utf-8') as f:
            chunk_index = json.load(f)
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_path.mkdir(parents=True, exist_ok=True)
        translated_chunks_dir = output_path / "translated_chunks"
        translated_chunks_dir.mkdir(exist_ok=True)
        
        # ë²ˆì—­ ì§„í–‰ ìƒí™© íŒŒì¼
        progress_file = output_path / "translation_progress.json"
        progress = self._load_progress(progress_file)
        
        # ë²ˆì—­ í†µê³„
        stats = {
            "total_chunks": len(chunk_index["chunks"]),
            "completed": len(progress.get("completed", [])),
            "failed": len(progress.get("failed", [])),
            "start_time": time.time(),
            "model_name": self.model_name
        }
        
        print(f"ğŸ“š ë²ˆì—­ ì‹œì‘: {stats['total_chunks']}ê°œ ì²­í¬")
        print(f"ğŸ¤– ëª¨ë¸: {self.model_name}")
        print(f"âœ… ì™„ë£Œ: {stats['completed']}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {stats['failed']}ê°œ")
        print("=" * 50)
        
        # ì§„í–‰ë°” ì„¤ì •
        pbar = tqdm(
            chunk_index["chunks"], 
            desc="ë²ˆì—­ ì§„í–‰",
            initial=stats['completed']
        )
        
        for chunk_info in pbar:
            chunk_file = chunk_info["file"]
            
            # ì´ë¯¸ ì™„ë£Œëœ ì²­í¬ ê±´ë„ˆë›°ê¸°
            if chunk_file in progress.get("completed", []):
                continue
            
            # ì²­í¬ íŒŒì¼ ì½ê¸°
            chunk_path = chunks_dir / chunk_file
            if not chunk_path.exists():
                print(f"ê²½ê³ : ì²­í¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {chunk_file}")
                progress.setdefault("failed", []).append(chunk_file)
                continue
            
            try:
                with open(chunk_path, 'r', encoding='utf-8') as f:
                    original_text = f.read()
                
                # ë²ˆì—­ ìˆ˜í–‰
                pbar.set_description(f"ë²ˆì—­ ì¤‘: {chunk_file}")
                translated_text = self.translate_text(original_text)
                
                if translated_text:
                    # ë²ˆì—­ ê²°ê³¼ ì €ì¥
                    output_file = translated_chunks_dir / f"ko_{chunk_file}"
                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write(translated_text)
                    
                    # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                    progress.setdefault("completed", []).append(chunk_file)
                    if chunk_file in progress.get("failed", []):
                        progress["failed"].remove(chunk_file)
                    
                    stats["completed"] += 1
                else:
                    # ì‹¤íŒ¨ ê¸°ë¡
                    progress.setdefault("failed", []).append(chunk_file)
                    stats["failed"] += 1
                    print(f"ì‹¤íŒ¨: {chunk_file}")
                
                # ì§„í–‰ ìƒí™© ì €ì¥
                self._save_progress(progress_file, progress)
                
            except Exception as e:
                print(f"ì˜¤ë¥˜ ì²˜ë¦¬ ì¤‘ {chunk_file}: {e}")
                progress.setdefault("failed", []).append(chunk_file)
                stats["failed"] += 1
                self._save_progress(progress_file, progress)
        
        pbar.close()
        
        # ë²ˆì—­ ì™„ë£Œ í†µê³„
        stats["end_time"] = time.time()
        stats["duration"] = stats["end_time"] - stats["start_time"]
        
        # ë²ˆì—­ ì¸ë±ìŠ¤ ìƒì„±
        self._create_translation_index(output_path, chunk_index, stats)
        
        return stats
    
    def _load_progress(self, progress_file: Path) -> Dict:
        """ë²ˆì—­ ì§„í–‰ ìƒí™© ë¡œë“œ"""
        if progress_file.exists():
            try:
                with open(progress_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception:
                pass
        return {"completed": [], "failed": []}
    
    def _save_progress(self, progress_file: Path, progress: Dict):
        """ë²ˆì—­ ì§„í–‰ ìƒí™© ì €ì¥"""
        try:
            with open(progress_file, 'w', encoding='utf-8') as f:
                json.dump(progress, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ì§„í–‰ ìƒí™© ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def _create_translation_index(self, output_path: Path, original_index: Dict, stats: Dict):
        """ë²ˆì—­ ì¸ë±ìŠ¤ íŒŒì¼ ìƒì„±"""
        translation_index = {
            "translation_info": {
                "model": self.model_name,
                "temperature": self.temperature,
                "start_time": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(stats["start_time"])),
                "end_time": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(stats["end_time"])),
                "duration_minutes": round(stats["duration"] / 60, 2),
                "total_chunks": stats["total_chunks"],
                "completed_chunks": stats["completed"],
                "failed_chunks": stats["failed"]
            },
            "original_info": original_index
        }
        
        index_file = output_path / "translation_index.json"
        with open(index_file, 'w', encoding='utf-8') as f:
            json.dump(translation_index, f, ensure_ascii=False, indent=2)

def main():
    """ë²ˆì—­ê¸° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Ollama ë²ˆì—­ê¸°")
    parser.add_argument("input_dir", help="ì…ë ¥ ë””ë ‰í† ë¦¬ (ì²­í¬ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬)")
    parser.add_argument("output_dir", help="ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--model", default="llama3.1:8b", help="Ollama ëª¨ë¸ëª…")
    parser.add_argument("--url", default="http://localhost:11434", help="Ollama ì„œë²„ URL")
    parser.add_argument("--temperature", type=float, default=0.1, help="ë²ˆì—­ ì˜¨ë„")
    
    args = parser.parse_args()
    
    # ë²ˆì—­ê¸° ì´ˆê¸°í™”
    translator = OllamaTranslator(
        model_name=args.model,
        base_url=args.url,
        temperature=args.temperature
    )
    
    # ì—°ê²° í™•ì¸
    if not translator.check_ollama_connection():
        print("âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ì„œë²„ URL: {args.url}")
        print("Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    if not translator.check_model_available():
        print(f"âŒ ëª¨ë¸ '{args.model}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ í™•ì¸í•´ì£¼ì„¸ìš”: ollama list")
        return
    
    print("âœ… Ollama ì—°ê²° í™•ì¸ ì™„ë£Œ")
    
    # ë²ˆì—­ ìˆ˜í–‰
    try:
        stats = translator.translate_chunks(args.input_dir, args.output_dir)
        
        print("\n" + "=" * 50)
        print("ğŸ“Š ë²ˆì—­ ì™„ë£Œ!")
        print(f"ì´ ì²­í¬: {stats['total_chunks']}ê°œ")
        print(f"ì™„ë£Œ: {stats['completed']}ê°œ")
        print(f"ì‹¤íŒ¨: {stats['failed']}ê°œ")
        print(f"ì†Œìš” ì‹œê°„: {stats['duration'] / 60:.1f}ë¶„")
        print(f"ë²ˆì—­ ê²°ê³¼: {args.output_dir}")
        
    except Exception as e:
        print(f"âŒ ë²ˆì—­ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()